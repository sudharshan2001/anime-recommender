{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "450816f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eac1b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf=pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a147fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dataf.copy()\n",
    "df1=df1[['uid','synopsis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2a06a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_remove=df1[df1['synopsis']=='No synopsis information has been added to this title. Help improve our database by adding a synopsis'].index.to_list()\n",
    "df1=df1.drop(df1.index[[to_remove]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f5ded97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "to_remove=df1[df1['synopsis']=='No synopsis information has been added to this title. Help improve our database by adding a synopsis'].index.to_list()\n",
    "print(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e657338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "def lemmatize(text):\n",
    "    try: \n",
    "        sentence = re.compile('[' +re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "        text = sentence.sub(\" \", text) \n",
    "        \n",
    "        word_tokens = [word_tokenize(i) for i in sent_tokenize(text)]\n",
    "        \n",
    "        tokens = []\n",
    "        for j in word_tokens:\n",
    "            tokens += j\n",
    "            \n",
    "        tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "        lowcase = [w for w in tokens if re.search('[a-zA-Z]', w)]\n",
    "        lowcase = [w.lower() for w in lowcase if len(w)>=3]\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized = [lemmatizer.lemmatize(word) for word in lowcase if len(word)>1]\n",
    "        return lemmatized[:-3]\n",
    "            \n",
    "    except TypeError:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1fe8a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['lemmat']=df1['synopsis'].map(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cd75affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2d0410d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>lemmat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28891</td>\n",
       "      <td>Following their participation at the Inter-Hig...</td>\n",
       "      <td>[following, participation, inter, high, karasu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23273</td>\n",
       "      <td>Music accompanies the path of the human metron...</td>\n",
       "      <td>[music, accompanies, path, human, metronome, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34599</td>\n",
       "      <td>The Abyss—a gaping chasm stretching down into ...</td>\n",
       "      <td>[abyss—a, gaping, chasm, stretching, depth, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5114</td>\n",
       "      <td>\"In order for something to be obtained, someth...</td>\n",
       "      <td>[order, something, obtained, something, equal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31758</td>\n",
       "      <td>After helping revive the legendary vampire Kis...</td>\n",
       "      <td>[helping, revive, legendary, vampire, kiss, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15609</th>\n",
       "      <td>10075</td>\n",
       "      <td>All-new animation offered throughout UNIQLO cl...</td>\n",
       "      <td>[new, animation, offered, throughout, uniqlo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15610</th>\n",
       "      <td>35828</td>\n",
       "      <td>High school student Sora Kashiwagi is accustom...</td>\n",
       "      <td>[high, school, student, sora, kashiwagi, accus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15611</th>\n",
       "      <td>10378</td>\n",
       "      <td>After regaining her squid-like abilities, Ika ...</td>\n",
       "      <td>[regaining, squid, like, ability, ika, musume,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15612</th>\n",
       "      <td>33082</td>\n",
       "      <td>For years, the Niflheim Empire and the kingdom...</td>\n",
       "      <td>[year, niflheim, empire, kingdom, lucis, war, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15613</th>\n",
       "      <td>16934</td>\n",
       "      <td>Although Yuuta Togashi and Rikka Takanashi hav...</td>\n",
       "      <td>[although, yuuta, togashi, rikka, takanashi, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15614 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                                           synopsis  \\\n",
       "0      28891  Following their participation at the Inter-Hig...   \n",
       "1      23273  Music accompanies the path of the human metron...   \n",
       "2      34599  The Abyss—a gaping chasm stretching down into ...   \n",
       "3       5114  \"In order for something to be obtained, someth...   \n",
       "4      31758  After helping revive the legendary vampire Kis...   \n",
       "...      ...                                                ...   \n",
       "15609  10075  All-new animation offered throughout UNIQLO cl...   \n",
       "15610  35828  High school student Sora Kashiwagi is accustom...   \n",
       "15611  10378  After regaining her squid-like abilities, Ika ...   \n",
       "15612  33082  For years, the Niflheim Empire and the kingdom...   \n",
       "15613  16934  Although Yuuta Togashi and Rikka Takanashi hav...   \n",
       "\n",
       "                                                  lemmat  \n",
       "0      [following, participation, inter, high, karasu...  \n",
       "1      [music, accompanies, path, human, metronome, p...  \n",
       "2      [abyss—a, gaping, chasm, stretching, depth, ea...  \n",
       "3      [order, something, obtained, something, equal,...  \n",
       "4      [helping, revive, legendary, vampire, kiss, sh...  \n",
       "...                                                  ...  \n",
       "15609  [new, animation, offered, throughout, uniqlo, ...  \n",
       "15610  [high, school, student, sora, kashiwagi, accus...  \n",
       "15611  [regaining, squid, like, ability, ika, musume,...  \n",
       "15612  [year, niflheim, empire, kingdom, lucis, war, ...  \n",
       "15613  [although, yuuta, togashi, rikka, takanashi, s...  \n",
       "\n",
       "[15614 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1d3b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('synopsis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f883f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_transformed = count.fit_transform(df1['synopsis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26ced44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similar = cosine_similarity(count_transformed, count_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fefc55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index()\n",
    "indices = pd.Series(df1.index, index=df1['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0758a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(uid, cosine_sim):\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[indices[uid]]))\n",
    "\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    return dataf['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b734997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\get_recommendations(28891, cosine_sim=cosine_similar).values[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3bca12e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735                                              Haikyuu!!\n",
       "1673                            Hataraku Saibou 2nd Season\n",
       "9330                                            Gan to Gon\n",
       "3229                             Hei Mao Jing Zhang (1992)\n",
       "11489                                             Paradise\n",
       "447                                         Diamond no Ace\n",
       "648                            Kuroko no Basket 2nd Season\n",
       "10413                                              Berserk\n",
       "13358    Tottoko Hamtarou: Best Hit Ham-chan'zu Music Clip\n",
       "10373                                        Qualidea Code\n",
       "557                                       Kuroko no Basket\n",
       "14106                                           Happiness!\n",
       "5884                     Diamond no Ace: Second Season OVA\n",
       "626                          Diamond no Ace: Second Season\n",
       "4931                                          Armitage III\n",
       "1049     Girls & Panzer: Kore ga Hontou no Anzio-sen Desu!\n",
       "4927                     Uchuu Senkan Yamato: Fukkatsu-hen\n",
       "1130                      Attack No.1: Namida no Fushichou\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf['title'].iloc[[j for j in movie_indices if 'Haikyuu!!:' not in dataf['title'].iloc[j].split(' ')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8e555623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haikyuu!!'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = pd.Series(dataf.index, index=dataf['uid'])\n",
    "dataf['title'].iloc[indices[28891]].split(' ')[0].replace(':','') not in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c3f7e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_ = pd.read_pickle(r'genre.pkl')\n",
    "gen_sim = cosine_similarity(object_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eac68421",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = dataf.loc[dataf['uid']==28891].index[0]\n",
    "recommended_lst = list(enumerate(gen_sim[location]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21557e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_lst = sorted(recommended_lst, key = lambda x:x[1] ,reverse=True)\n",
    "recommended_lst = recommended_lst[1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1d2f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=dataf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5442594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_i = [j[0] for j in recommended_lst]\n",
    "final_list = [i for i in movie_i if 'Season' not in df_full['title'].iloc[i]]\n",
    "indices = pd.Series(df_full.index, index=df_full['uid'])\n",
    "final_list=[j for j in final_list if df_full['title'].iloc[indices[28891]].split(' ')[0].replace(':','') not in df_full['title'].iloc[j].split(' ')]\n",
    "recommended_series = df_full['title'].iloc[final_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7ec50349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       Haikyuu!!: Karasuno Koukou vs. Shiratorizawa G...\n",
       "705                                              Slam Dunk\n",
       "1338                                         Batsu & Terry\n",
       "1390                                     Rokudenashi Blues\n",
       "1675                                 Haikyuu!!: To the Top\n",
       "1676                               Haikyuu!!: Riku vs. Kuu\n",
       "5798                                         Ahiru no Sora\n",
       "539                                     Ballroom e Youkoso\n",
       "659                                             Cross Game\n",
       "13687                               Rokudenashi Blues 1993\n",
       "176                              Kuroko no Basket: Tip Off\n",
       "323        Tennis no Ouji-sama: Zenkoku Taikai-hen - Final\n",
       "418                           Yowamushi Pedal: Grande Road\n",
       "431                       Hajime no Ippo: Boxer no Kobushi\n",
       "447                                         Diamond no Ace\n",
       "502                                 Diamond no Ace: Act II\n",
       "516                                         Major: Message\n",
       "547                                               Major S4\n",
       "557                                       Kuroko no Basket\n",
       "571                                    Major: World Series\n",
       "587                                               Major S1\n",
       "618                                               Major S6\n",
       "734                                 Hajime no Ippo: Rising\n",
       "745                         Hajime no Ippo: New Challenger\n",
       "761                                         Hajime no Ippo\n",
       "777                                               Major S2\n",
       "785                                        Yowamushi Pedal\n",
       "911                               Kuroko no Basket NG-shuu\n",
       "941                        Yowamushi Pedal: New Generation\n",
       "1031     Tennis no Ouji-sama: Another Story - Kako to M...\n",
       "1047              Kuroko no Basket: Mou Ikkai Yarimasen ka\n",
       "4782                  Kuroko no Basket: Oshaberi Shiyou ka\n",
       "5013                                 Yowamushi Pedal Movie\n",
       "5062                        Yowamushi Pedal: Re:Generation\n",
       "5147                                  Houkago no Ouji-sama\n",
       "5282              Kuroko no Basket: Baka ja Katenai no yo!\n",
       "5512                           Yowamushi Pedal: Spare Bike\n",
       "5599                                        Major 2nd (TV)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3296cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
